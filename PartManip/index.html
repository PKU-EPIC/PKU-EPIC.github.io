<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>PartManip</title>
    <!-- Bootstrap -->
    <link rel="preconnect" href="https://rsms.me/">
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css"> -->
    <style>
      body {
        background: rgb(255, 255, 255) no-repeat fixed top left; 
        font-family: "Inter", 'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container-fluid">
        <div class="row">
          <div class="col">
            <h2 style="font-size:30px;">PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations</h2>
            <h4 style="color:#6e6e6e;"> CVPR 2023 </h4>
            <hr>
            <h6>
              <a href="https://geng-haoran.github.io/" target="_blank">Haoran Geng</a><sup>1, 2*</sup>&nbsp; &nbsp;
              Ziming Li<sup>1,2*</sup> &nbsp; &nbsp;
              <a href="https://gengyiran.github.io/" target="_blank">Yiran Geng</a><sup>1, 2</sup>&nbsp; &nbsp;
              <a href="https://jychen18.github.io/" target="_blank">Jiayi Chen</a><sup>1,3</sup>&nbsp; &nbsp;
              <a href="https://zsdonghao.github.io/" target="_blank">Hao Dong</a><sup>1,2</sup> &nbsp; &nbsp;
              <a href="https://hughw19.github.io/" target="_blank">He Wang</a><sup>1,2†</sup>&nbsp; &nbsp;
              <br>
              <br>
            <p> 
              <sup>1</sup>CFCS, Peking University&nbsp; &nbsp; 
              <sup>2</sup>School of EECS, Peking University&nbsp; &nbsp;  
              <sup>3</sup>Beijing Academy of Artificial Intelligence&nbsp; &nbsp; 
              <br>
            </p>
            <p> <sup>*</sup> equal contributions &nbsp;
              <sup>†</sup> corresponding author &nbsp;
              <br>
          </p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5">
                    <a class="btn btn-large btn-light" href="https://arxiv.org/abs/2303.16958" role="button" target="_blank">
                    <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5">
                    <a class="btn btn-large btn-light" href="https://github.com/PKU-EPIC/PartManip" role="button" target="_blank">
                <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                <p class="mb-5">
                  <a class="btn btn-large btn-light" href="https://forms.gle/DqdPvLE6pNWZf2XR8" role="button" target="_blank">
              <i class="fa fa-github-alt"></i> Dataset </a> </p>
            </div>
              <!-- <div class="column">
                  <p class="mb-5">
                    <a class="btn btn-large btn-light" href="./index.html" role="button" target="_blank" style="pointer-events: none">
                <i class="fa fa-github-alt"></i> Dataset (Coming soon) </a> </p>
              </div> -->
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="./index.html" role="button" target="_blank" style="pointer-events: none">
                <i class="fa fa-github-alt"></i> Dataset (Coming soon) </a> </p>
              </div> -->
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>


  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <hr style="margin-top:0px">
              <div class="row justify-content-center" style="align-items:center; display:flex;">
               <img src="images/teaser_img.png" alt="input" class="img-responsive graph" width="95%"/>
              <br>
            </div>
            <p class="text-justify">
               We introduce a <b>large-scale cross-category part manipulation benchmark <i>PartManip</i></b>  with <b>diverse object datasets</b>,
               <b>realistic settings</b>, and <b>rich annotations</b>. We propose a <b>generalizable vision-based policy learning strategy</b> and boost the performance of
                part-based object manipulation by a large margin, which can generalize to <b>unseen object categories</b> and novel objects in the real world.
            </p>
              <!-- </div> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Video</strong></h2>
            <hr style="margin-top:0px">
            <div style="display: flex; justify-content: center;">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/k0LbcO1B-ac" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
            <!-- <div class="row justify-content-center" style="align-items:center; display:flex;">
              <video width="80%" playsinline="" preload="" muted="" controls>
                <source src="video/PartManip_video.mp4" type="video/mp4">
              </video>
            </div>   -->
        </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Abstract</strong></h2>
            <hr style="margin-top:0px">
              <!-- <div class="row justify-content-center" style="align-items:center; display:flex;">
               <img src="images/teaser.png" alt="input" class="img-responsive" width="95%"/>
              <br>
            </div> -->
          <!-- <p class="text-justify">
              <h6 style="color:#8899a5;text-align:left"> Figure 1. Framework overview (From the left to right): we leverage domain randomization-enhanced depth simulation to generate paired data, on which we can train our depth restoration network SwinDRNet, and the restored depths will be fed to downstream tasks and improves estimating category-level pose and grasping for specular and transparent objects.</h6>
          </p> -->
            <p class="text-justify">
              Learning a generalizable object manipulation policy is
              vital for an embodied agent to work in complex real-world
              scenes. Parts, as the shared components in different object
              categories, have the potential to increase the generaliza-
              tion ability of the manipulation policy and achieve cross-
              category object manipulation. In this work, we build <b>the
              first large-scale, part-based cross-category object manip-
              ulation benchmark, PartManip</b>, which is composed of 11
              object categories, 494 objects, and 1432 tasks in 6 task
              classes. Compared to previous work, our benchmark is
              also more diverse and realistic, i.e., having more objects
              and using sparse-view point cloud as input without oracle
              information like part segmentation. To tackle the difficul-
              ties of vision-based policy learning, we first train a <b>state-
              based expert</b> with our proposed part-based canonicaliza-
              tion and part-aware rewards, and then <b>distill the knowledge
              to a vision-based student</b>. We also find an expressive back-
              bone is essential to overcome the large diversity of different
              objects. For <b>cross-category generalization</b>, we introduce
              domain adversarial learning for domain-invariant feature
              extraction. Extensive experiments in simulation show that
              our learned policy can outperform other methods by a large
              margin, especially on unseen object categories. We also
              demonstrate our method can successfully manipulate novel
              objects in the real world.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Benchmark -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>PartManip Benchmark</strong></h2>
            <hr style="margin-top:0px">
            <!-- <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>objects</b></h3> -->
              <p class="text-justify">
                By utilizing the definition of the generalizable and actionable part (<b>GAPart</b>) 
                  presented in GAPartNet, we build a benchmark for a comprehensive evaluation of the
                  <b>cross-category generalization</b> policy learning approaches. GAParts are some kinds
                  of parts that have similar geometry and similar interaction strategy across 
                  different object categories. For example, the handle on tables is often similar 
                  to those on safes, so we can regard the handle as a GAPart. The nature of GAPart
                  ensures a general way for manipulation <b>regardless of the object category</b>,
                  making it possible for cross-category generalization. We thus expect the 
                  manipulation policy trained on some object categories can generalize to other 
                  unseen object categories, and build <b>the first benchmark for cross-category 
                  generalizable part manipulation policy learning</b>. 
              </p>    
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/objs.jpg" alt="input" class="img-responsive graph" width="95%"/>
              </div>
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/objs_table.jpg" alt="input" class="img-responsive graph" width="95%"/>
              </div>
              <p class="text-justify">
                Furthermore, our benchmark 
                  is more <b>diverse</b> and <b>realistic</b> than previous robotic manipulation benchmarks. 
                  Diversity indicates that we have more object instances and categories. 
                  Realism indicates that our observation space has less 
                  oracle information (i.e., part segmentation masks)
              </p>

              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/tasks.jpg" alt="input" class="img-responsive graph" width="95%"/>
              </div>
            <br>
            <p class="text-justify">
              We have six classes of tasks:<b>OpenDoor</b>, <b>OpenDrawer</b>, <b>CloseDoor</b>, <b>CloseDrawer</b>, 
              <b>PressButton</b> and <b>GraspHandle</b>. Although OpenDoor and OpenDrawer require grasping 
                the handle first, GraspHandle differs from them because it contains another GAPart 
                lid with more object categories.
            </p>

            
        </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Methods -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Methods</strong></h2>
            <hr style="margin-top:0px">
            <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Full pipeline</b></h3>
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/pipe.png" alt="input" class="img-responsive graph" width="95%"/>
              </div>
              <p class="text-justify">
                <b>An Overview of Our Pipeline.</b>  
                We first train <b>state-based expert policy</b> using our proposed <b>canonicalization to the 
                part coordinate frame</b> and the <b>part-aware reward</b>. We then use the learned expert to 
                collect demonstrations for pre-training the vision-based policy by <b>behavior cloning</b>. 
                After pre-training, we train the vision-based policy to imitate the state-based expert 
                policy using <b>DAgger</b>. We also introduce several point cloud augmentation techniques 
                to boost the generalization ability. For the vision backbone, we introduce <b>3D 
                Sparse-UNet</b> which has a large expression capability. Furthermore, we introduced an 
                extra <b>domain adversarial learning module</b> for better cross-category generalization.
              </p>
            <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Training</b></h3>
            <div class="row justify-content-center" style="align-items:center; display:flex;">
              <video width="80%" playsinline="" preload="" muted="" controls>
                <source src="video/PartManip_train.mp4" type="video/mp4">
              </video>
            </div>  
            <br>
            <p class="text-justify">
              We use Isaac Gym as our simulator and most experiments are done in simulation.
              During training, we can <b>parallelly</b> train on <b>multiple different objects</b> in our simulators.
            </p>
            


        </div>
        </div>
      </div>
    </div>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Quantitative results</strong></h2>
            <hr style="margin-top:0px">
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/result1.jpg" alt="input" class="img-responsive graph" width="60%"/>
              </div>
              <p class="text-justify">
                This is the quantitative result of Opening Door. Our method outperforms other 
                baselines by a large margins, especially in <b>unseen categories</b>.
              </p>
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/result2.jpg" alt="input" class="img-responsive graph" width="60%"/>
              </div>
              <p class="text-justify">
                The same goes for the opening drawer task. Our method still achieve state-of-the-art 
                performance, especially in <b>unseen categories</b>.
              </p>
            <br>
        </div>
        </div>
      </div>
    </div>


  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Qualitative results</strong></h2>
          <hr style="margin-top:0px">
          <div class="row justify-content-center" style="align-items:center; display:flex;">
            <img src="video/sim.gif" alt="input" class="img-responsive graph" width="60%"/>
          </div>
          <p class="text-justify">
          This qualitative results show our training results. Compared to previous works, our policy
          is <b>part-aware</b> and thus more similar to <b>human behaviors</b>. For example, our policy can use 
          handles to open doors and drawers, as shown in our video.
          </p>
          <div class="row justify-content-center" style="align-items:center; display:flex;">
            <img src="video/real.gif" alt="input" class="img-responsive graph" width="100%"/>
          </div>
          <p class="text-justify">
            We also apply the output action of our policy to the robotic arm both in the simulator 
            and the real world. Note that the testing object is unseen during policy learning. 
            Experiments show that our trained model can <b>successfully transfer to the real world</b>.
          </p>
        </div>
        </div>
      </div>
    </div>


  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h2><strong>Citation</strong></h2>
          <hr style="margin-top:0px">
            <pre style="background-color: #e9eeef;padding: 0 1.5em">
            <code>           
@article{geng2023partmanip,
  title={PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations},
  author={Geng, Haoran and Li, Ziming and Geng, Yiran and Chen, Jiayi and Dong, Hao and Wang, He},
  journal={arXiv preprint arXiv:2303.16958},
  year={2023}
}

@article{geng2022gapartnet,
  title={GAPartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts},
  author={Geng, Haoran and Xu, Helin and Zhao, Chengyang and Xu, Chao and Yi, Li and Huang, Siyuan and Wang, He},
  journal={arXiv preprint arXiv:2211.05272},
  year={2022}
}</code>
            </pre>
      </div>
    </div>
  </div>
  <br>

    <!-- Contact -->
    <div class="container">
      <div class="row ">
        <div class="col-12">
            <h2><strong>Contact</strong></h2>
            <hr style="margin-top:0px">
            <p>If you have any questions, please feel free to contact us:
              <ul>
                <li><b>Haoran Geng</b>&colon; ghr<span style="display:none">Prevent spamming</span>@<span style="display:none">Prevent spamming</span>stu.pku.edu.cn </li>
                <li><b>He Wang</b>&colon; hewang<span style="display:none">Prevent spamming</span>@<span style="display:none">Prevent spamming</span>pku.edu.cn </li>
              </ul>
            </p>
        </pre>
        </div>
      </div>
    </div>


      
    <a href="https://hits.seeyoufarm.com">
      <img id="myImage" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fpku-epic.github.io%2FPartManip%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/>
      <script>
        function hideImage() {
            document.getElementById("myImage").style.display = "none";
        }
        window.onload = hideImage;
      </script>
    </a>

  <footer class="text-center" style="margin-bottom:10px; font-size: medium;">
      <hr>
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
  </footer>
  <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']],
      macros: {
        bm: ["{\\boldsymbol #1}",1],
      }}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>
</html>
